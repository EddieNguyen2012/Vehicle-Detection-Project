{
<<<<<<< HEAD
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jTKSpQmfvCl",
        "outputId": "1a18ec18-0f3a-4ee1-f475-5ca71ca1d048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.16.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LcfhkMvO97kA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF9d3Rs-3bOm",
        "outputId": "a806c19c-7022-48cb-c5a2-d799233983d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UsakXbzP5sQB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Define paths to your image folders\n",
        "# non_vehicle_folder = \"vehicle_dataset/non-vehicles/\"\n",
        "# vehicle_folder = \"vehicle_dataset/vehicles/\"\n",
        "\n",
        "# # Step 1: List Image Files using os.listdir()\n",
        "# non_vehicle_files = [os.path.join(non_vehicle_folder, file) for file in os.listdir(non_vehicle_folder) if file.endswith('.png')]\n",
        "# vehicle_files = [os.path.join(vehicle_folder, file) for file in os.listdir(vehicle_folder) if file.endswith('.png')]\n",
        "\n",
        "# # Step 2: Create Dataset with Labels\n",
        "# non_vehicle_dataset = tf.data.Dataset.from_tensor_slices((non_vehicle_files, [1] * len(non_vehicle_files)))\n",
        "# vehicle_dataset = tf.data.Dataset.from_tensor_slices((vehicle_files, [2] * len(vehicle_files)))\n",
        "\n",
        "# # Step 3: Combine Datasets\n",
        "# image_dataset = non_vehicle_dataset.concatenate(vehicle_dataset)\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "dataset = 'vehicle_dataset'\n",
        "\n",
        "for folder in os.listdir(dataset):\n",
        "    if not folder.startswith('.'):\n",
        "        label = None\n",
        "\n",
        "        if folder in ['vehicles']: label = 0\n",
        "        elif folder in ['non-vehicles']: label = 1\n",
        "\n",
        "        for file in os.listdir(os.path.join(dataset, folder)):\n",
        "            if file.endswith('.png'):\n",
        "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
        "\n",
        "                image = cv2.imread(img_path)\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "images = np.array(images, dtype='float32')/255.0\n",
        "labels = np.array(labels, dtype='int32')\n",
        "\n",
        "images = images.reshape(-1,64,64,3)\n",
        "\n",
        "images, labels = shuffle(images, labels, random_state=42)\n",
        "\n",
        "# train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size = 0.2)\n",
        "xtrain,xval,ytrain,yval=train_test_split(images, labels,train_size=0.8,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 64, 3)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "OOP6IYPW99HB",
        "outputId": "08383d61-9226-4bcf-ffc8-5e26bcc463de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidtan/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# # Define the model architecture\n",
        "# class SSDModel(tf.keras.Model):\n",
        "#     def __init__(self, num_classes):\n",
        "#         super(SSDModel, self).__init__()\n",
        "#         self.num_classes = num_classes\n",
        "\n",
        "#         # Backbone network (e.g. VGG16)\n",
        "#         self.backbone = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "#         # Feature extractor layers\n",
        "#         self.feature_extractor = tf.keras.Sequential([\n",
        "#             tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same'),\n",
        "#             tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same'),\n",
        "#             tf.keras.layers.MaxPooling2D((2, 2))\n",
        "#         ])\n",
        "\n",
        "#         # SSD layers\n",
        "#         self.ssd_layers = []\n",
        "#         for i in range(6):  # 6 default boxes per feature map\n",
        "#             self.ssd_layers.append(SSDLayer(4 + i, num_classes))\n",
        "\n",
        "#         # Prediction layers\n",
        "#         self.prediction_layers = []\n",
        "#         for i in range(6):  # 6 feature maps\n",
        "#             self.prediction_layers.append(PredictionLayer(num_classes))\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         # Backbone network\n",
        "#         x = self.backbone(inputs)\n",
        "\n",
        "#         # Feature extractor layers\n",
        "#         x = self.feature_extractor(x)\n",
        "\n",
        "#         # SSD layers\n",
        "#         feature_maps = []\n",
        "#         for i, layer in enumerate(self.ssd_layers):\n",
        "#             print(layer)\n",
        "#             x, feature_map = layer(x)\n",
        "#             feature_maps.append(feature_map)\n",
        "\n",
        "#         # Prediction layers\n",
        "#         predictions = []\n",
        "#         for i, layer in enumerate(self.prediction_layers):\n",
        "#             predictions.append(layer(feature_maps[i]))\n",
        "\n",
        "#         # Concatenate predictions\n",
        "#         predictions = tf.concat(predictions, axis=1)\n",
        "\n",
        "#         return predictions\n",
        "\n",
        "# class SSDLayer(tf.keras.layers.Layer):\n",
        "#     def __init__(self, num_defaults, num_classes):\n",
        "#         super(SSDLayer, self).__init__()\n",
        "#         self.num_defaults = num_defaults\n",
        "#         self.num_classes = num_classes\n",
        "\n",
        "#     def build(self, input_shape):\n",
        "#         self.conv = tf.keras.layers.Conv2D(self.num_defaults * (4 + self.num_classes), (3, 3), activation='linear', padding='same', input_shape=input_shape)\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         # inputs = tf.reshape(inputs, (-1, 64, 64, 3))  # Reshape inputs here\n",
        "#         inputs = tf.reshape(inputs, (-1, 32, 32, 3))  # Assuming 3 channels (RGB)\n",
        "#         x = self.conv(inputs)\n",
        "#         x = tf.reshape(x, (-1, x.shape[1], x.shape[2], self.num_defaults, 4 + self.num_classes))\n",
        "#         return x, x[:, :, :, :, :4]\n",
        "\n",
        "# class PredictionLayer(tf.keras.layers.Layer):\n",
        "#     def __init__(self, num_classes):\n",
        "#         super(PredictionLayer, self).__init__()\n",
        "#         self.num_classes = num_classes\n",
        "\n",
        "#     def build(self, input_shape):\n",
        "#         self.conv = tf.keras.layers.Conv2D(self.num_classes, (3, 3), activation='softmax', padding='same', input_shape=input_shape)\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         x = self.conv(inputs)\n",
        "#         return x\n",
        "\n",
        "# def load_image(file_path, label):\n",
        "#     img = tf.io.read_file(file_path)\n",
        "#     img = tf.image.decode_image(img, channels=3)  # Ensure 3 channels for color images\n",
        "#     img = tf.cast(img, tf.uint8)  # Cast the image to uint8 data type\n",
        "#     return img, label\n",
        "\n",
        "\n",
        "# # Create the model\n",
        "# model = SSDModel(num_classes=2)  # 2 classes: vehicle and non-vehicle\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='ssd_loss', metrics=['accuracy'])\n",
        "\n",
        "#\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", activation='relu', input_shape=(64,64,3)))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        " \n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam' ,metrics=['accuracy'])\n",
        "\n",
        "# # Create a dataset object\n",
        "# dataset = image_dataset.map(load_image)\n",
        "\n",
        "# # # Define the size of the training set\n",
        "# # train_size = int(0.8 * dataset.cardinality().numpy())\n",
        "\n",
        "\n",
        "# # # Split the dataset into training and testing subsets\n",
        "# # train_dataset = dataset.take(train_size)\n",
        "# # test_dataset = dataset.skip(train_size)\n",
        "\n",
        "# # Convert dataset to list to calculate train_size\n",
        "# dataset_list = list(dataset)\n",
        "# train_size = int(0.8 * len(dataset_list))\n",
        "\n",
        "# # Split the dataset into training and testing subsets\n",
        "# train_dataset = tf.data.Dataset.from_tensor_slices(dataset_list[:train_size])\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices(dataset_list[train_size:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        featurewise_center=False,  \n",
        "        samplewise_center=False,  \n",
        "        featurewise_std_normalization=False,  \n",
        "        samplewise_std_normalization=False,  \n",
        "        zca_whitening=False,    \n",
        "        rotation_range=15,    \n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,  \n",
        "        horizontal_flip=True,  \n",
        "        vertical_flip=False)\n",
        "datagen.fit(xtrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 215ms/step - accuracy: 0.8663 - loss: 0.3078 - val_accuracy: 0.9724 - val_loss: 0.0739\n",
            "Epoch 2/5\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 210ms/step - accuracy: 0.9777 - loss: 0.0709 - val_accuracy: 0.9820 - val_loss: 0.0496\n",
            "Epoch 3/5\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 219ms/step - accuracy: 0.9844 - loss: 0.0477 - val_accuracy: 0.9797 - val_loss: 0.0684\n",
            "Epoch 4/5\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 215ms/step - accuracy: 0.9851 - loss: 0.0455 - val_accuracy: 0.9870 - val_loss: 0.0353\n",
            "Epoch 5/5\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 214ms/step - accuracy: 0.9873 - loss: 0.0402 - val_accuracy: 0.9901 - val_loss: 0.0305\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2e1c3ab90>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(xtrain, ytrain, batch_size=32,\n",
        "                    epochs=5,\n",
        "                    verbose=1,\n",
        "                    validation_data=(xval, yval))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
=======
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jTKSpQmfvCl",
    "outputId": "1a18ec18-0f3a-4ee1-f475-5ca71ca1d048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LcfhkMvO97kA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF9d3Rs-3bOm",
    "outputId": "a806c19c-7022-48cb-c5a2-d799233983d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UsakXbzP5sQB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your image folders\n",
    "non_vehicle_folder = \"vehicle_dataset/non-vehicles/\"\n",
    "vehicle_folder = \"vehicle_dataset/vehicles/\"\n",
    "\n",
    "# Step 1: List Image Files using os.listdir()\n",
    "non_vehicle_files = [os.path.join(non_vehicle_folder, file) for file in os.listdir(non_vehicle_folder) if file.endswith('.png')]\n",
    "vehicle_files = [os.path.join(vehicle_folder, file) for file in os.listdir(vehicle_folder) if file.endswith('.png')]\n",
    "\n",
    "# Step 2: Create Dataset with Labels\n",
    "non_vehicle_dataset = tf.data.Dataset.from_tensor_slices((non_vehicle_files, [1] * len(non_vehicle_files)))\n",
    "vehicle_dataset = tf.data.Dataset.from_tensor_slices((vehicle_files, [2] * len(vehicle_files)))\n",
    "\n",
    "# Step 3: Combine Datasets\n",
    "image_dataset = non_vehicle_dataset.concatenate(vehicle_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "OOP6IYPW99HB",
    "outputId": "08383d61-9226-4bcf-ffc8-5e26bcc463de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 17:03:36.106557: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Pack as input #1(zero-based) was expected to be a uint8 tensor but is a int32 tensor [Op:Pack] name: 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 105\u001B[0m\n\u001B[1;32m    102\u001B[0m train_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;241m0.8\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(dataset_list))\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# Split the dataset into training and testing subsets\u001B[39;00m\n\u001B[0;32m--> 105\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_tensor_slices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_list\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43mtrain_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    106\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_tensor_slices(dataset_list[train_size:])\n\u001B[1;32m    108\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:826\u001B[0m, in \u001B[0;36mDatasetV2.from_tensor_slices\u001B[0;34m(tensors, name)\u001B[0m\n\u001B[1;32m    822\u001B[0m \u001B[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001B[39;00m\n\u001B[1;32m    823\u001B[0m \u001B[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001B[39;00m\n\u001B[1;32m    824\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001B[39;00m\n\u001B[1;32m    825\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m from_tensor_slices_op\n\u001B[0;32m--> 826\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfrom_tensor_slices_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_from_tensor_slices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001B[0m, in \u001B[0;36m_from_tensor_slices\u001B[0;34m(tensors, name)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_from_tensor_slices\u001B[39m(tensors, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 25\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_TensorSliceDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001B[0m, in \u001B[0;36m_TensorSliceDataset.__init__\u001B[0;34m(self, element, is_files, name)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, element, is_files\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     32\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m   element \u001B[38;5;241m=\u001B[39m \u001B[43mstructure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize_element\u001B[49m\u001B[43m(\u001B[49m\u001B[43melement\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m   batched_spec \u001B[38;5;241m=\u001B[39m structure\u001B[38;5;241m.\u001B[39mtype_spec_from_value(element)\n\u001B[1;32m     35\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tensors \u001B[38;5;241m=\u001B[39m structure\u001B[38;5;241m.\u001B[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:110\u001B[0m, in \u001B[0;36mnormalize_element\u001B[0;34m(element, element_signature)\u001B[0m\n\u001B[1;32m    105\u001B[0m     spec \u001B[38;5;241m=\u001B[39m type_spec_from_value(t, use_fallback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    107\u001B[0m   \u001B[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001B[39;00m\n\u001B[1;32m    108\u001B[0m   \u001B[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001B[39;00m\n\u001B[1;32m    109\u001B[0m   normalized_components\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 110\u001B[0m       \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcomponent_\u001B[39;49m\u001B[38;5;132;43;01m%d\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    112\u001B[0m   \u001B[38;5;66;03m# To avoid a circular dependency between dataset_ops and structure,\u001B[39;00m\n\u001B[1;32m    113\u001B[0m   \u001B[38;5;66;03m# we check the class name instead of using `isinstance`.\u001B[39;00m\n\u001B[1;32m    114\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m spec\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetSpec\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001B[0m, in \u001B[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    181\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m Trace(trace_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtrace_kwargs):\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:713\u001B[0m, in \u001B[0;36mconvert_to_tensor\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001B[0m\n\u001B[1;32m    711\u001B[0m \u001B[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001B[39;00m\n\u001B[1;32m    712\u001B[0m preferred_dtype \u001B[38;5;241m=\u001B[39m preferred_dtype \u001B[38;5;129;01mor\u001B[39;00m dtype_hint\n\u001B[0;32m--> 713\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor_conversion_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    714\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreferred_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccepted_result_types\u001B[49m\n\u001B[1;32m    715\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001B[0m, in \u001B[0;36mconvert\u001B[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001B[0m\n\u001B[1;32m    225\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    226\u001B[0m           _add_error_prefix(\n\u001B[1;32m    227\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConversion function \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconversion_func\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m for type \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    230\u001B[0m               \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mactual = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mret\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mbase_dtype\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    231\u001B[0m               name\u001B[38;5;241m=\u001B[39mname))\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 234\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mconversion_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mas_ref\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_ref\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[1;32m    237\u001B[0m   \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1305\u001B[0m, in \u001B[0;36m_autopacking_conversion_function\u001B[0;34m(v, dtype, name, as_ref)\u001B[0m\n\u001B[1;32m   1303\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m dtype \u001B[38;5;241m!=\u001B[39m inferred_dtype:\n\u001B[1;32m   1304\u001B[0m   v \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mmap_structure(_cast_nested_seqs_to_dtype(dtype), v)\n\u001B[0;32m-> 1305\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_autopacking_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpacked\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1224\u001B[0m, in \u001B[0;36m_autopacking_helper\u001B[0;34m(list_or_tuple, dtype, name)\u001B[0m\n\u001B[1;32m   1222\u001B[0m   must_pack \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1223\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[0;32m-> 1224\u001B[0m   converted_elem \u001B[38;5;241m=\u001B[39m \u001B[43m_autopacking_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43melem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1225\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted_elem, core\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m   1226\u001B[0m     must_pack \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1212\u001B[0m, in \u001B[0;36m_autopacking_helper\u001B[0;34m(list_or_tuple, dtype, name)\u001B[0m\n\u001B[1;32m   1208\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m   1209\u001B[0m   \u001B[38;5;66;03m# NOTE: Fast path when all the items are tensors, this doesn't do any type\u001B[39;00m\n\u001B[1;32m   1210\u001B[0m   \u001B[38;5;66;03m# checking.\u001B[39;00m\n\u001B[1;32m   1211\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(elem, core\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;28;01mfor\u001B[39;00m elem \u001B[38;5;129;01min\u001B[39;00m list_or_tuple):\n\u001B[0;32m-> 1212\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_array_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlist_or_tuple\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1213\u001B[0m must_pack \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1214\u001B[0m converted_elems \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:6718\u001B[0m, in \u001B[0;36mpack\u001B[0;34m(values, axis, name)\u001B[0m\n\u001B[1;32m   6716\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   6717\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m-> 6718\u001B[0m   \u001B[43m_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from_not_ok_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6719\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_FallbackException:\n\u001B[1;32m   6720\u001B[0m   \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/CS171/FinalProject/Vehicle-Detection-Project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5983\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   5981\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NoReturn:\n\u001B[1;32m   5982\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m-> 5983\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: cannot compute Pack as input #1(zero-based) was expected to be a uint8 tensor but is a int32 tensor [Op:Pack] name: 0"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "class SSDModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SSDModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Backbone network (e.g. VGG16)\n",
    "        self.backbone = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "        # Feature extractor layers\n",
    "        self.feature_extractor = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        ])\n",
    "\n",
    "        # SSD layers\n",
    "        self.ssd_layers = []\n",
    "        for i in range(6):  # 6 default boxes per feature map\n",
    "            self.ssd_layers.append(SSDLayer(4 + i, num_classes))\n",
    "\n",
    "        # Prediction layers\n",
    "        self.prediction_layers = []\n",
    "        for i in range(6):  # 6 feature maps\n",
    "            self.prediction_layers.append(PredictionLayer(num_classes))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Backbone network\n",
    "        x = self.backbone(inputs)\n",
    "\n",
    "        # Feature extractor layers\n",
    "        x = self.feature_extractor(x)\n",
    "\n",
    "        # SSD layers\n",
    "        feature_maps = []\n",
    "        for i, layer in enumerate(self.ssd_layers):\n",
    "            x, feature_map = layer(x)\n",
    "            feature_maps.append(feature_map)\n",
    "\n",
    "        # Prediction layers\n",
    "        predictions = []\n",
    "        for i, layer in enumerate(self.prediction_layers):\n",
    "            predictions.append(layer(feature_maps[i]))\n",
    "\n",
    "        # Concatenate predictions\n",
    "        predictions = tf.concat(predictions, axis=1)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "class SSDLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_defaults, num_classes):\n",
    "        super(SSDLayer, self).__init__()\n",
    "        self.num_defaults = num_defaults\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv = tf.keras.layers.Conv2D(self.num_defaults * (4 + self.num_classes), (3, 3), activation='linear', padding='same', input_shape=input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = tf.reshape(x, (-1, x.shape[1], x.shape[2], self.num_defaults, 4 + self.num_classes))\n",
    "        return x, x[:, :, :, :, :4]\n",
    "\n",
    "class PredictionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PredictionLayer, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv = tf.keras.layers.Conv2D(self.num_classes, (3, 3), activation='softmax', padding='same', input_shape=input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        return x\n",
    "\n",
    "def load_image(file_path, label):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_image(img, channels=3)  # Ensure 3 channels for color images\n",
    "    img = tf.cast(img, tf.uint8)  # Cast the image to uint8 data type\n",
    "    return img, label\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = SSDModel(num_classes=2)  # 2 classes: vehicle and non-vehicle\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='ssd_loss', metrics=['accuracy'])\n",
    "\n",
    "# Create a dataset object\n",
    "dataset = image_dataset.map(load_image)\n",
    "\n",
    "# # Define the size of the training set\n",
    "# train_size = int(0.8 * dataset.cardinality().numpy())\n",
    "\n",
    "\n",
    "# # Split the dataset into training and testing subsets\n",
    "# train_dataset = dataset.take(train_size)\n",
    "# test_dataset = dataset.skip(train_size)\n",
    "\n",
    "# Convert dataset to list to calculate train_size\n",
    "dataset_list = list(dataset)\n",
    "train_size = int(0.8 * len(dataset_list))\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(dataset_list[:train_size])\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(dataset_list[train_size:])\n",
    "\n",
    "# Train the model\n",
    "# model.fit(train_dataset, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
>>>>>>> origin/initialmodel
}
